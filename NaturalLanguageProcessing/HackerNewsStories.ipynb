{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data:__ \"hn_stories_select.csv\" contains a selection of user submissions to Hacker News (http://news.ycombinator.com/) (3000 randomly sampled entries from 2006 to 2015). Developer Arnaud Drizard used the Hacker News API to scrape these data, which is available from one of his GitHub repositories at https://github.com/arnauddri/hn.\n",
    "\n",
    "Columns in data set:\n",
    "* submission_time - When the article was submitted\n",
    "* upvotes - The number of upvotes the article received\n",
    "* url - The base URL of the article\n",
    "* headline - The article's headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of the Data\n",
    "import pandas as pd\n",
    "submissions = pd.read_csv(\"hn_stories_select.csv\")\n",
    "submissions.columns = [\"submission_time\", \"upvotes\", \"url\", \"headline\"]\n",
    "submissions = submissions.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the Headlines\n",
    "tokenized_headlines = []\n",
    "\n",
    "for i in submissions.headline:\n",
    "    tokenized_headlines.append( i.split(\" \") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing Tokens to Increase Accuracy\n",
    "punctuation = [\",\", \":\", \";\", \".\", \"'\", '\"', \"â€™\", \"?\", \"/\", \"-\", \"+\", \"&\", \"(\", \")\"]\n",
    "clean_tokenized = []\n",
    "\n",
    "for item in tokenized_headlines:\n",
    "    tokens = []\n",
    "    for token in item:\n",
    "        token = token.lower()\n",
    "        for punc in punctuation:\n",
    "            token = token.replace(punc, \"\")\n",
    "        tokens.append(token)\n",
    "    clean_tokenized.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assembling a Matrix of Unique Words\n",
    "import numpy as np\n",
    "unique_tokens = []\n",
    "single_tokens = []\n",
    "\n",
    "#flat_list = [item for sublist in clean_tokenized for item in sublist]\n",
    "\n",
    "# Print top words in cleaned-up input data\n",
    "#import collections\n",
    "#ncount = 500\n",
    "#print ( collections.Counter(flat_list).most_common(ncount) )\n",
    "\n",
    "unique_tokens_firstencounter = []\n",
    "unique_tokens = []\n",
    "\n",
    "for list in clean_tokenized:\n",
    "    for token in list:\n",
    "        if ( token in unique_tokens ):\n",
    "            continue\n",
    "        elif ( token in unique_tokens_firstencounter ):\n",
    "            unique_tokens.append( token )\n",
    "        else:\n",
    "            \n",
    "            unique_tokens_firstencounter.append(token)\n",
    "            \n",
    "counts = pd.DataFrame(0, index=np.arange(len(clean_tokenized)), columns=unique_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting Token Occurrences\n",
    "\n",
    "# We've already loaded in clean_tokenized and counts\n",
    "\n",
    "for row, list in enumerate(clean_tokenized):\n",
    "    for token in list:\n",
    "        if ( token in unique_tokens ):\n",
    "            counts.iloc[row][token] = counts.iloc[row][token]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing Columns to Increase Accuracy\n",
    "\n",
    "word_counts = counts.sum(axis=0)\n",
    "\n",
    "word_counts_bool = [ (i >= 5) & (i <= 100 ) for i in word_counts ]\n",
    "\n",
    "counts = counts.loc[:,word_counts_bool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Split data set into train and test samples\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, submissions[\"upvotes\"], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Making Predictions With fit()\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "clf = LinearRegression()\n",
    "\n",
    "clf.fit( X_train, y_train )\n",
    "predictions = clf.predict( X_test )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Mean Squared Error (https://en.wikipedia.org/wiki/Mean_squared_error) to quantify prediction error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  2652.60825125\n"
     ]
    }
   ],
   "source": [
    "# Calculating Prediction Error\n",
    "\n",
    "mse = np.sum( (predictions-y_test)**2 )\n",
    "mse /= len( predictions )\n",
    "\n",
    "print ( \"Mean Squared Error: \", mse )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take several steps to reduce the error and explore natural language processing further. Here are some ideas for your next steps:\n",
    "\n",
    "* Use the entire data set. While we used samples in this mission, you could download the entire data set from this GitHub repository. This approach will reduce the error rate dramatically. There are many features in natural language processing. Using more data will ensure that the model will find more occurrences of the same features in the test and training sets, which will help the model make better predictions.\n",
    "* Add \"meta\" features like headline length and average word length.\n",
    "* Use a random forest, or another more powerful machine learning technique.\n",
    "* Explore different thresholds for removing extraneous columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
